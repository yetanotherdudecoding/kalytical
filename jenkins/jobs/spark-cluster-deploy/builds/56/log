Started by user [8mha:////4Nct9mT4JkcR2n6qL2qp2Se2jSWIXugywtK/9phaDtIgAAAAmB+LCAAAAAAAAP9b85aBtbiIQTGjNKU4P08vOT+vOD8nVc83PyU1x6OyILUoJzMv2y+/JJUBAhiZGBgqihhk0NSjKDWzXb3RdlLBUSYGJk8GtpzUvPSSDB8G5tKinBIGIZ+sxLJE/ZzEvHT94JKizLx0a6BxUmjGOUNodHsLgAzuEgYe/dLi1CL9lPzk7NQiAErXYGvBAAAA[0mzzz@zzz.com
Building in workspace /var/jenkins_home/workspace/spark-cluster-deploy
 > git rev-parse --is-inside-work-tree # timeout=10
Fetching changes from the remote Git repository
 > git config remote.origin.url https://zerodown524@bitbucket.org/zerodown524/kalytical.git # timeout=10
Fetching upstream changes from https://zerodown524@bitbucket.org/zerodown524/kalytical.git
 > git --version # timeout=10
using GIT_ASKPASS to set credentials 
 > git fetch --tags --progress https://zerodown524@bitbucket.org/zerodown524/kalytical.git +refs/heads/*:refs/remotes/origin/*
 > git rev-parse refs/remotes/origin/initial^{commit} # timeout=10
 > git rev-parse refs/remotes/origin/origin/initial^{commit} # timeout=10
Checking out Revision 401572340397d162ae37571b0ac69b64be98ee95 (refs/remotes/origin/initial)
 > git config core.sparsecheckout # timeout=10
 > git checkout -f 401572340397d162ae37571b0ac69b64be98ee95
Commit message: "fix magnitude for memory"
 > git rev-list --no-walk 38b1ffee225eca4b2deb558d59afe1a911377efc # timeout=10
[spark-cluster-deploy] $ docker build -t instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster:56 --pull=true --file=spark/master/Dockerfile spark/master
Sending build context to Docker daemon  2.048kB
Step 1/1 : FROM gettyimages/spark:latest
Trying to pull repository docker.io/gettyimages/spark ... 
latest: Pulling from docker.io/gettyimages/spark
Digest: sha256:476fe6243bfd172064d7f71bd1d3679618f349e09941420848dde08c9fa6cf16
Status: Image is up to date for docker.io/gettyimages/spark:latest
 ---> 56107fdf8422
Successfully built 56107fdf8422
[spark-cluster-deploy] $ docker tag 56107fdf8422 instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster:latest
[spark-cluster-deploy] $ docker inspect 56107fdf8422
[spark-cluster-deploy] $ docker push instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster:56
The push refers to a repository [instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster]
b499c54f8f4e: Preparing
fae276ab8af7: Preparing
158c017de1af: Preparing
9821ca65a1a8: Preparing
8d43435b20d7: Preparing
90d1009ce6fe: Preparing
90d1009ce6fe: Waiting
9821ca65a1a8: Layer already exists
158c017de1af: Layer already exists
8d43435b20d7: Layer already exists
b499c54f8f4e: Layer already exists
fae276ab8af7: Layer already exists
90d1009ce6fe: Layer already exists
56: digest: sha256:476fe6243bfd172064d7f71bd1d3679618f349e09941420848dde08c9fa6cf16 size: 1591
[spark-cluster-deploy] $ docker push instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster:latest
The push refers to a repository [instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster]
b499c54f8f4e: Preparing
fae276ab8af7: Preparing
158c017de1af: Preparing
9821ca65a1a8: Preparing
8d43435b20d7: Preparing
90d1009ce6fe: Preparing
90d1009ce6fe: Waiting
fae276ab8af7: Layer already exists
9821ca65a1a8: Layer already exists
b499c54f8f4e: Layer already exists
8d43435b20d7: Layer already exists
158c017de1af: Layer already exists
90d1009ce6fe: Layer already exists
latest: digest: sha256:476fe6243bfd172064d7f71bd1d3679618f349e09941420848dde08c9fa6cf16 size: 1591
[spark-cluster-deploy] $ docker build -t instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker:56 --pull=true --file=spark/worker/Dockerfile spark/worker
Sending build context to Docker daemon  4.608kB
Step 1/4 : FROM gettyimages/spark:latest
Trying to pull repository docker.io/gettyimages/spark ... 
latest: Pulling from docker.io/gettyimages/spark
Digest: sha256:476fe6243bfd172064d7f71bd1d3679618f349e09941420848dde08c9fa6cf16
Status: Image is up to date for docker.io/gettyimages/spark:latest
 ---> 56107fdf8422
Step 2/4 : COPY startWorker.sh startWorker.sh
 ---> Using cache
 ---> 092ad9f6f321
Step 3/4 : RUN chmod +x startWorker.sh
 ---> Using cache
 ---> f8857ac9126f
Step 4/4 : CMD /bin/bash ./startWorker.sh
 ---> Using cache
 ---> 728d8f7c67cc
Successfully built 728d8f7c67cc
[spark-cluster-deploy] $ docker tag 728d8f7c67cc instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker:latest
[spark-cluster-deploy] $ docker inspect 728d8f7c67cc
[spark-cluster-deploy] $ docker push instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker:56
The push refers to a repository [instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker]
cfcea9ec6d4c: Preparing
1856dfc241e5: Preparing
b499c54f8f4e: Preparing
fae276ab8af7: Preparing
158c017de1af: Preparing
9821ca65a1a8: Preparing
8d43435b20d7: Preparing
90d1009ce6fe: Preparing
9821ca65a1a8: Waiting
8d43435b20d7: Waiting
90d1009ce6fe: Waiting
b499c54f8f4e: Layer already exists
1856dfc241e5: Layer already exists
fae276ab8af7: Layer already exists
158c017de1af: Layer already exists
cfcea9ec6d4c: Layer already exists
8d43435b20d7: Layer already exists
9821ca65a1a8: Layer already exists
90d1009ce6fe: Layer already exists
56: digest: sha256:dd6b6db3becac2035fa468cea1672b91e506549cb9a28f7e25058a13bed96cf1 size: 2005
[spark-cluster-deploy] $ docker push instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker:latest
The push refers to a repository [instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker]
cfcea9ec6d4c: Preparing
1856dfc241e5: Preparing
b499c54f8f4e: Preparing
fae276ab8af7: Preparing
158c017de1af: Preparing
9821ca65a1a8: Preparing
8d43435b20d7: Preparing
90d1009ce6fe: Preparing
9821ca65a1a8: Waiting
8d43435b20d7: Waiting
90d1009ce6fe: Waiting
158c017de1af: Layer already exists
cfcea9ec6d4c: Layer already exists
fae276ab8af7: Layer already exists
b499c54f8f4e: Layer already exists
8d43435b20d7: Layer already exists
90d1009ce6fe: Layer already exists
9821ca65a1a8: Layer already exists
1856dfc241e5: Layer already exists
latest: digest: sha256:dd6b6db3becac2035fa468cea1672b91e506549cb9a28f7e25058a13bed96cf1 size: 2005
Starting Kubernetes deployment
Loading configuration: /var/jenkins_home/workspace/spark-cluster-deploy/spark/spark-cluster-deploy.yaml
Applied Service: Service(apiVersion=v1, kind=Service, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-17T16:30:38Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels=null, name=spark-cluster-01-spark-master, namespace=bsavoy, ownerReferences=[], resourceVersion=112761, selfLink=/api/v1/namespaces/bsavoy/services/spark-cluster-01-spark-master, uid=169d79e1-0219-11e9-85de-42010a8e0003, additionalProperties={}), spec=ServiceSpec(clusterIP=10.105.11.56, externalIPs=[], externalName=null, externalTrafficPolicy=Cluster, healthCheckNodePort=null, loadBalancerIP=null, loadBalancerSourceRanges=[], ports=[ServicePort(name=null, nodePort=30707, port=7077, protocol=TCP, targetPort=IntOrString(IntVal=7077, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={})], selector={app=spark-master-spark-cluster-01}, sessionAffinity=None, type=NodePort, additionalProperties={}), status=ServiceStatus(loadBalancer=LoadBalancerStatus(ingress=[], additionalProperties={}), additionalProperties={}), additionalProperties={})
Applied Service: Service(apiVersion=v1, kind=Service, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-17T16:30:38Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels=null, name=spark-cluster-01-spark-ui, namespace=bsavoy, ownerReferences=[], resourceVersion=113535, selfLink=/api/v1/namespaces/bsavoy/services/spark-cluster-01-spark-ui, uid=16a152e8-0219-11e9-85de-42010a8e0003, additionalProperties={}), spec=ServiceSpec(clusterIP=10.108.228.255, externalIPs=[], externalName=null, externalTrafficPolicy=Cluster, healthCheckNodePort=null, loadBalancerIP=null, loadBalancerSourceRanges=[], ports=[ServicePort(name=null, nodePort=30888, port=8080, protocol=TCP, targetPort=IntOrString(IntVal=8080, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={})], selector={app=spark-master-spark-cluster-01}, sessionAffinity=None, type=NodePort, additionalProperties={}), status=ServiceStatus(loadBalancer=LoadBalancerStatus(ingress=[], additionalProperties={}), additionalProperties={}), additionalProperties={})
Applied Service: Service(apiVersion=v1, kind=Service, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-19T16:05:17Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels=null, name=spark-cluster-01-spark-app-ui, namespace=bsavoy, ownerReferences=[], resourceVersion=178343, selfLink=/api/v1/namespaces/bsavoy/services/spark-cluster-01-spark-app-ui, uid=e0cf4730-03a7-11e9-9dff-42010a8e0003, additionalProperties={}), spec=ServiceSpec(clusterIP=10.106.129.241, externalIPs=[], externalName=null, externalTrafficPolicy=Cluster, healthCheckNodePort=null, loadBalancerIP=null, loadBalancerSourceRanges=[], ports=[ServicePort(name=null, nodePort=30413, port=4040, protocol=TCP, targetPort=IntOrString(IntVal=4040, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={})], selector={app=spark-worker-spark-cluster-01}, sessionAffinity=None, type=NodePort, additionalProperties={}), status=ServiceStatus(loadBalancer=LoadBalancerStatus(ingress=[], additionalProperties={}), additionalProperties={}), additionalProperties={})
Applied Deployment: Deployment(apiVersion=extensions/v1beta1, kind=Deployment, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-17T16:30:38Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=15, initializers=null, labels={app=spark-master-spark-cluster-01}, name=spark-master-spark-cluster-01, namespace=bsavoy, ownerReferences=[], resourceVersion=180639, selfLink=/apis/extensions/v1beta1/namespaces/bsavoy/deployments/spark-master-spark-cluster-01, uid=16a3317c-0219-11e9-85de-42010a8e0003, additionalProperties={}), spec=DeploymentSpec(minReadySeconds=null, paused=null, progressDeadlineSeconds=2147483647, replicas=1, revisionHistoryLimit=2147483647, rollbackTo=null, selector=LabelSelector(matchExpressions=[], matchLabels={app=spark-master-spark-cluster-01}, additionalProperties={}), strategy=DeploymentStrategy(rollingUpdate=RollingUpdateDeployment(maxSurge=IntOrString(IntVal=1, Kind=null, StrVal=null, additionalProperties={}), maxUnavailable=IntOrString(IntVal=1, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={}), type=RollingUpdate, additionalProperties={}), template=PodTemplateSpec(metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels={app=spark-master-spark-cluster-01}, name=null, namespace=null, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=PodSpec(activeDeadlineSeconds=null, affinity=null, automountServiceAccountToken=null, containers=[Container(args=[], command=[], env=[EnvVar(name=PYSPARK_PYTHON, value=python3, valueFrom=null, additionalProperties={}), EnvVar(name=PYSPARK_DRIVER_PYTHON, value=python3, valueFrom=null, additionalProperties={})], envFrom=[], image=instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkmaster:56, imagePullPolicy=IfNotPresent, lifecycle=null, livenessProbe=null, name=spark-master-spark-cluster-01, ports=[], readinessProbe=null, resources=ResourceRequirements(limits={cpu=Quantity(amount=1, format=null, additionalProperties={}), memory=Quantity(amount=2Gi, format=null, additionalProperties={})}, requests={cpu=Quantity(amount=500m, format=null, additionalProperties={}), memory=Quantity(amount=1Gi, format=null, additionalProperties={})}, additionalProperties={}), securityContext=null, stdin=null, stdinOnce=null, terminationMessagePath=/dev/termination-log, terminationMessagePolicy=File, tty=null, volumeMounts=[], workingDir=null, additionalProperties={})], dnsPolicy=ClusterFirst, hostAliases=[], hostIPC=null, hostNetwork=null, hostPID=null, hostname=null, imagePullSecrets=[], initContainers=[], nodeName=null, nodeSelector=null, restartPolicy=Always, schedulerName=default-scheduler, securityContext=PodSecurityContext(fsGroup=null, runAsNonRoot=null, runAsUser=null, seLinuxOptions=null, supplementalGroups=[], additionalProperties={}), serviceAccount=null, serviceAccountName=null, subdomain=null, terminationGracePeriodSeconds=30, tolerations=[], volumes=[], additionalProperties={}), additionalProperties={}), additionalProperties={}), status=DeploymentStatus(availableReplicas=1, collisionCount=null, conditions=[DeploymentCondition(lastTransitionTime=2018-12-17T16:30:38Z, lastUpdateTime=2018-12-17T16:30:38Z, message=Deployment has minimum availability., reason=MinimumReplicasAvailable, status=True, type=Available, additionalProperties={})], observedGeneration=14, readyReplicas=1, replicas=1, unavailableReplicas=null, updatedReplicas=1, additionalProperties={}), additionalProperties={})
Applied Deployment: Deployment(apiVersion=extensions/v1beta1, kind=Deployment, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-17T16:30:38Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=21, initializers=null, labels={app=spark-worker-spark-cluster-01}, name=spark-cluster-01-spark-worker, namespace=bsavoy, ownerReferences=[], resourceVersion=180649, selfLink=/apis/extensions/v1beta1/namespaces/bsavoy/deployments/spark-cluster-01-spark-worker, uid=16a5326d-0219-11e9-85de-42010a8e0003, additionalProperties={}), spec=DeploymentSpec(minReadySeconds=null, paused=null, progressDeadlineSeconds=2147483647, replicas=1, revisionHistoryLimit=2147483647, rollbackTo=null, selector=LabelSelector(matchExpressions=[], matchLabels={app=spark-worker-spark-cluster-01}, additionalProperties={}), strategy=DeploymentStrategy(rollingUpdate=RollingUpdateDeployment(maxSurge=IntOrString(IntVal=1, Kind=null, StrVal=null, additionalProperties={}), maxUnavailable=IntOrString(IntVal=1, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={}), type=RollingUpdate, additionalProperties={}), template=PodTemplateSpec(metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels={app=spark-worker-spark-cluster-01}, name=null, namespace=null, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=PodSpec(activeDeadlineSeconds=null, affinity=null, automountServiceAccountToken=null, containers=[Container(args=[], command=[], env=[EnvVar(name=SPARK_MASTER_URL, value=spark-cluster-01-spark-master:7077, valueFrom=null, additionalProperties={}), EnvVar(name=PYSPARK_PYTHON, value=python3, valueFrom=null, additionalProperties={}), EnvVar(name=PYSPARK_DRIVER_PYTHON, value=python3, valueFrom=null, additionalProperties={}), EnvVar(name=SPARK_WORKER_MEMORY, value=4096, valueFrom=null, additionalProperties={}), EnvVar(name=SPARK_WORKER_CORES, value=1M, valueFrom=null, additionalProperties={})], envFrom=[], image=instance-1.us-east1-b.c.sandbox-224519.internal:8080/sparkworker:56, imagePullPolicy=IfNotPresent, lifecycle=null, livenessProbe=null, name=spark-worker-spark-cluster-01, ports=[], readinessProbe=null, resources=ResourceRequirements(limits={cpu=Quantity(amount=1, format=null, additionalProperties={}), memory=Quantity(amount=4Gi, format=null, additionalProperties={})}, requests=null, additionalProperties={}), securityContext=null, stdin=null, stdinOnce=null, terminationMessagePath=/dev/termination-log, terminationMessagePolicy=File, tty=null, volumeMounts=[], workingDir=null, additionalProperties={})], dnsPolicy=ClusterFirst, hostAliases=[], hostIPC=null, hostNetwork=null, hostPID=null, hostname=null, imagePullSecrets=[], initContainers=[], nodeName=null, nodeSelector=null, restartPolicy=Always, schedulerName=default-scheduler, securityContext=PodSecurityContext(fsGroup=null, runAsNonRoot=null, runAsUser=null, seLinuxOptions=null, supplementalGroups=[], additionalProperties={}), serviceAccount=null, serviceAccountName=null, subdomain=null, terminationGracePeriodSeconds=30, tolerations=[], volumes=[], additionalProperties={}), additionalProperties={}), additionalProperties={}), status=DeploymentStatus(availableReplicas=null, collisionCount=null, conditions=[DeploymentCondition(lastTransitionTime=2018-12-19T16:31:41Z, lastUpdateTime=2018-12-19T16:31:41Z, message=Deployment has minimum availability., reason=MinimumReplicasAvailable, status=True, type=Available, additionalProperties={})], observedGeneration=20, readyReplicas=null, replicas=1, unavailableReplicas=1, updatedReplicas=1, additionalProperties={}), additionalProperties={})
Finished Kubernetes deployment
Finished: SUCCESS
