Started by user [8mha:////4Nct9mT4JkcR2n6qL2qp2Se2jSWIXugywtK/9phaDtIgAAAAmB+LCAAAAAAAAP9b85aBtbiIQTGjNKU4P08vOT+vOD8nVc83PyU1x6OyILUoJzMv2y+/JJUBAhiZGBgqihhk0NSjKDWzXb3RdlLBUSYGJk8GtpzUvPSSDB8G5tKinBIGIZ+sxLJE/ZzEvHT94JKizLx0a6BxUmjGOUNodHsLgAzuEgYe/dLi1CL9lPzk7NQiAErXYGvBAAAA[0mzzz@zzz.com
Building in workspace /var/jenkins_home/workspace/testjenkins
 > git rev-parse --is-inside-work-tree # timeout=10
Fetching changes from the remote Git repository
 > git config remote.origin.url https://zerodown524@bitbucket.org/zerodown524/k8s-python-test-app.git # timeout=10
Fetching upstream changes from https://zerodown524@bitbucket.org/zerodown524/k8s-python-test-app.git
 > git --version # timeout=10
 > git fetch --tags --progress https://zerodown524@bitbucket.org/zerodown524/k8s-python-test-app.git +refs/heads/*:refs/remotes/origin/*
 > git rev-parse refs/remotes/origin/master^{commit} # timeout=10
 > git rev-parse refs/remotes/origin/origin/master^{commit} # timeout=10
Checking out Revision 30be7baacab9593566a1c542b96d6240e2fd482d (refs/remotes/origin/master)
 > git config core.sparsecheckout # timeout=10
 > git checkout -f 30be7baacab9593566a1c542b96d6240e2fd482d
Commit message: "pytest_deployment.yaml edited online with Bitbucket"
 > git rev-list --no-walk 30be7baacab9593566a1c542b96d6240e2fd482d # timeout=10
[testjenkins] $ docker build -t instance-2:8080/pytest:11 --pull=true /var/jenkins_home/workspace/testjenkins
Sending build context to Docker daemon  100.4kB
Step 1/7 : FROM python:2.7-slim
Trying to pull repository docker.io/library/python ... 
2.7-slim: Pulling from docker.io/library/python
Digest: sha256:f82db224fbc9ff3309b7b62496e19d673738a568891604a12312e237e01ef147
Status: Image is up to date for docker.io/python:2.7-slim
 ---> 0dc3d8d47241
Step 2/7 : WORKDIR /usr/src/app
 ---> Using cache
 ---> a8880d7527d2
Step 3/7 : RUN pip install --upgrade pip
 ---> Using cache
 ---> f1278bbe2c02
Step 4/7 : RUN pip install --upgrade setuptools
 ---> Using cache
 ---> 4fc05d63f4ec
Step 5/7 : COPY ./pytest.py ./
 ---> Using cache
 ---> 7ee29bdba58d
Step 6/7 : CMD python ./pytest.py
 ---> Using cache
 ---> 8a1016637267
Step 7/7 : EXPOSE 8080
 ---> Using cache
 ---> a83d18d69265
Successfully built a83d18d69265
[testjenkins] $ docker tag a83d18d69265 instance-2:8080/pytest:latest
[testjenkins] $ docker inspect a83d18d69265
[testjenkins] $ docker push instance-2:8080/pytest:11
The push refers to a repository [instance-2:8080/pytest]
e77e6808d194: Preparing
3f8615609bcf: Preparing
fa8944ef28d4: Preparing
9f8a6958baf4: Preparing
6cffeea81e5d: Preparing
614a79865f6d: Preparing
612d27bb923f: Preparing
ef68f6734aa4: Preparing
614a79865f6d: Waiting
612d27bb923f: Waiting
ef68f6734aa4: Waiting
9f8a6958baf4: Layer already exists
3f8615609bcf: Layer already exists
fa8944ef28d4: Layer already exists
6cffeea81e5d: Layer already exists
e77e6808d194: Layer already exists
612d27bb923f: Layer already exists
614a79865f6d: Layer already exists
ef68f6734aa4: Layer already exists
11: digest: sha256:1adbcb4e6e40a6225ec966aa74d50466236216b865f8bfec8e085e5c1077af34 size: 1999
[testjenkins] $ docker push instance-2:8080/pytest:latest
The push refers to a repository [instance-2:8080/pytest]
e77e6808d194: Preparing
3f8615609bcf: Preparing
fa8944ef28d4: Preparing
9f8a6958baf4: Preparing
6cffeea81e5d: Preparing
614a79865f6d: Preparing
612d27bb923f: Preparing
ef68f6734aa4: Preparing
614a79865f6d: Waiting
612d27bb923f: Waiting
ef68f6734aa4: Waiting
e77e6808d194: Layer already exists
9f8a6958baf4: Layer already exists
fa8944ef28d4: Layer already exists
6cffeea81e5d: Layer already exists
3f8615609bcf: Layer already exists
612d27bb923f: Layer already exists
ef68f6734aa4: Layer already exists
614a79865f6d: Layer already exists
latest: digest: sha256:1adbcb4e6e40a6225ec966aa74d50466236216b865f8bfec8e085e5c1077af34 size: 1999
Starting Kubernetes deployment
Loading configuration: /var/jenkins_home/workspace/testjenkins/pytest_deployment.yaml
Applied Service: Service(apiVersion=v1, kind=Service, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-13T19:49:29Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels=null, name=pytest-service, namespace=bsavoy, ownerReferences=[], resourceVersion=57879, selfLink=/api/v1/namespaces/bsavoy/services/pytest-service, uid=34330713-ff10-11e8-a61f-42010a8e0003, additionalProperties={}), spec=ServiceSpec(clusterIP=10.99.217.28, externalIPs=[], externalName=null, externalTrafficPolicy=Cluster, healthCheckNodePort=null, loadBalancerIP=null, loadBalancerSourceRanges=[], ports=[ServicePort(name=null, nodePort=31872, port=8080, protocol=TCP, targetPort=IntOrString(IntVal=8080, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={})], selector={app=pytest}, sessionAffinity=None, type=NodePort, additionalProperties={}), status=ServiceStatus(loadBalancer=LoadBalancerStatus(ingress=[], additionalProperties={}), additionalProperties={}), additionalProperties={})
Applied Deployment: Deployment(apiVersion=extensions/v1beta1, kind=Deployment, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2018-12-13T19:49:29Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=4, initializers=null, labels={app=pytest}, name=pytest-deployment, namespace=bsavoy, ownerReferences=[], resourceVersion=64791, selfLink=/apis/extensions/v1beta1/namespaces/bsavoy/deployments/pytest-deployment, uid=34526e0a-ff10-11e8-a61f-42010a8e0003, additionalProperties={}), spec=DeploymentSpec(minReadySeconds=null, paused=null, progressDeadlineSeconds=2147483647, replicas=5, revisionHistoryLimit=2147483647, rollbackTo=null, selector=LabelSelector(matchExpressions=[], matchLabels={app=pytest}, additionalProperties={}), strategy=DeploymentStrategy(rollingUpdate=RollingUpdateDeployment(maxSurge=IntOrString(IntVal=1, Kind=null, StrVal=null, additionalProperties={}), maxUnavailable=IntOrString(IntVal=1, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={}), type=RollingUpdate, additionalProperties={}), template=PodTemplateSpec(metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels={app=pytest}, name=null, namespace=null, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=PodSpec(activeDeadlineSeconds=null, affinity=null, automountServiceAccountToken=null, containers=[Container(args=[], command=[], env=[], envFrom=[], image=instance-2:8080/pytest:11, imagePullPolicy=IfNotPresent, lifecycle=null, livenessProbe=Probe(exec=null, failureThreshold=3, httpGet=HTTPGetAction(host=null, httpHeaders=[], path=healthcheck, port=IntOrString(IntVal=8080, Kind=null, StrVal=null, additionalProperties={}), scheme=HTTP, additionalProperties={}), initialDelaySeconds=8, periodSeconds=10, successThreshold=1, tcpSocket=null, timeoutSeconds=8, additionalProperties={}), name=pytest-og, ports=[ContainerPort(containerPort=8080, hostIP=null, hostPort=null, name=null, protocol=TCP, additionalProperties={})], readinessProbe=Probe(exec=null, failureThreshold=3, httpGet=HTTPGetAction(host=null, httpHeaders=[], path=healthcheck, port=IntOrString(IntVal=8080, Kind=null, StrVal=null, additionalProperties={}), scheme=HTTP, additionalProperties={}), initialDelaySeconds=8, periodSeconds=10, successThreshold=1, tcpSocket=null, timeoutSeconds=8, additionalProperties={}), resources=ResourceRequirements(limits={cpu=Quantity(amount=400m, format=null, additionalProperties={}), memory=Quantity(amount=512Mi, format=null, additionalProperties={})}, requests={cpu=Quantity(amount=50m, format=null, additionalProperties={}), memory=Quantity(amount=32Mi, format=null, additionalProperties={})}, additionalProperties={}), securityContext=null, stdin=null, stdinOnce=null, terminationMessagePath=/dev/termination-log, terminationMessagePolicy=File, tty=null, volumeMounts=[], workingDir=null, additionalProperties={})], dnsPolicy=ClusterFirst, hostAliases=[], hostIPC=null, hostNetwork=null, hostPID=null, hostname=null, imagePullSecrets=[], initContainers=[], nodeName=null, nodeSelector=null, restartPolicy=Always, schedulerName=default-scheduler, securityContext=PodSecurityContext(fsGroup=null, runAsNonRoot=null, runAsUser=null, seLinuxOptions=null, supplementalGroups=[], additionalProperties={}), serviceAccount=null, serviceAccountName=null, subdomain=null, terminationGracePeriodSeconds=30, tolerations=[], volumes=[], additionalProperties={}), additionalProperties={}), additionalProperties={}), status=DeploymentStatus(availableReplicas=null, collisionCount=null, conditions=[DeploymentCondition(lastTransitionTime=2018-12-13T19:49:29Z, lastUpdateTime=2018-12-13T19:49:29Z, message=Deployment does not have minimum availability., reason=MinimumReplicasUnavailable, status=False, type=Available, additionalProperties={})], observedGeneration=3, readyReplicas=null, replicas=6, unavailableReplicas=6, updatedReplicas=2, additionalProperties={}), additionalProperties={})
Skipped unsupported resource: HorizontalPodAutoscaler(apiVersion=autoscaling/v2beta1, kind=HorizontalPodAutoscaler, metadata=ObjectMeta(annotations={}, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels={}, name=pytest-hpa, namespace=bsavoy, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=HorizontalPodAutoscalerSpec(maxReplicas=20, minReplicas=5, scaleTargetRef=CrossVersionObjectReference(apiVersion=apps/v1, kind=Deployment, name=pytest-deployment, additionalProperties={}), targetCPUUtilizationPercentage=null, additionalProperties={}), status=null, additionalProperties={})
Finished Kubernetes deployment
Finished: SUCCESS
